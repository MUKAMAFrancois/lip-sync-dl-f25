{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Universal Path Setup"
      ],
      "metadata": {
        "id": "4FMuaMtaqpdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# --- 1. Universal Path Setup ---\n",
        "# Automatically detect if we are in Colab/Kaggle or a persistent HPC folder\n",
        "CURRENT_DIR = Path.cwd()\n",
        "REPO_NAME = \"lip-sync-dl-f25\"\n",
        "REPO_URL = \"https://github.com/MUKAMAFrancois/lip-sync-dl-f25.git\"\n",
        "\n",
        "print(f\"üìç Current Working Directory: {CURRENT_DIR}\")\n",
        "\n",
        "# If the repo folder doesn't exist, clone it\n",
        "if not (CURRENT_DIR / REPO_NAME).exists() and not (CURRENT_DIR / \".git\").exists():\n",
        "    print(\"‚¨áÔ∏è Cloning repository...\")\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL], check=True)\n",
        "    os.chdir(REPO_NAME)\n",
        "elif (CURRENT_DIR / REPO_NAME).exists():\n",
        "    os.chdir(REPO_NAME)\n",
        "\n",
        "print(f\"üìÇ Execution Root: {Path.cwd()}\")\n",
        "\n",
        "# --- 2. Robust Dependency Installation ---\n",
        "print(\"üì¶ Installing Dependencies...\")\n",
        "\n",
        "# Force uninstallation of incompatible numpy versions common in new environments\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"numpy\"], stdout=subprocess.DEVNULL)\n",
        "\n",
        "# Install strict requirements\n",
        "# Note: --no-deps on some packages to prevent them from upgrading numpy back to 2.x\n",
        "commands = [\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numpy<2.0\"],\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements.txt\"],\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"face-alignment\", \"pytorch-fid\", \"kagglehub\", \"--no-deps\"],\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"opencv-python-headless<4.8\"], # Downgrade for stability\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"librosa==0.10.1\"]\n",
        "]\n",
        "\n",
        "for cmd in commands:\n",
        "    subprocess.run(cmd, check=False)\n",
        "\n",
        "print(\"‚úÖ Environment Ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ5pCuExkuUv",
        "outputId": "deea19fe-1ff4-447e-bcb9-c8f5ffe62be6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìç Current Working Directory: /content\n",
            "‚¨áÔ∏è Cloning repository...\n",
            "üìÇ Execution Root: /content/lip-sync-dl-f25\n",
            "üì¶ Installing Dependencies...\n",
            "‚úÖ Environment Ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Wav2Lip & Checkpoints"
      ],
      "metadata": {
        "id": "PzOtxCsHql0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Setup Wav2Lip & Checkpoints ---\n",
        "import os\n",
        "\n",
        "# 1. Run the setup script to clone Wav2Lip if missing\n",
        "print(\"‚öôÔ∏è Setting up Wav2Lip Submodule...\")\n",
        "if not os.path.exists(\"setup_wav2lip.py\"):\n",
        "    print(\"‚ùå Error: setup_wav2lip.py not found. Are you in the right directory?\")\n",
        "else:\n",
        "    !python setup_wav2lip.py\n",
        "\n",
        "# 2. Verify Checkpoints\n",
        "checkpoints = [\"checkpoints/wav2lip_gan.pth\", \"checkpoints/lipsync_expert.pth\"]\n",
        "missing = [c for c in checkpoints if not os.path.exists(c)]\n",
        "\n",
        "if not missing:\n",
        "    print(\"‚úÖ All checkpoints verified.\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Missing checkpoints: {missing}. Retrying setup...\")\n",
        "    !python setup_wav2lip.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMrnZxTCqTPb",
        "outputId": "03bc8455-f31b-48c3-a0bc-f5528b10131b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Setting up Wav2Lip Submodule...\n",
            "‚¨áÔ∏è Cloning Wav2Lip into /content/lip-sync-dl-f25/Wav2Lip...\n",
            "Cloning into 'Wav2Lip'...\n",
            "remote: Enumerating objects: 409, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 409 (delta 2), reused 0 (delta 0), pack-reused 405 (from 2)\u001b[K\n",
            "Receiving objects: 100% (409/409), 549.28 KiB | 21.13 MiB/s, done.\n",
            "Resolving deltas: 100% (227/227), done.\n",
            "‚¨áÔ∏è Downloading wav2lip_gan.pth...\n",
            "‚¨áÔ∏è Downloading lipsync_expert.pth...\n",
            "‚úÖ Setup Complete.\n",
            "‚úÖ All checkpoints verified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "HlMJM553qugR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Download Dataset ---\n",
        "print(\"‚¨áÔ∏è Downloading Dataset via KaggleHub...\")\n",
        "# Note: On PSC/HPC, ensure you have internet access or upload data manually to 'data/german'\n",
        "try:\n",
        "    path = kagglehub.dataset_download(\"francoismukama/muavic-german-sample\")\n",
        "\n",
        "    target = Path(\"data/german\")\n",
        "    target.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Source path from kagglehub download\n",
        "    src_root = Path(path) / \"mtedx/video/de\"\n",
        "\n",
        "    # Copy splits (Train/Val/Test)\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        src = src_root / split\n",
        "        # Handle 'val' vs 'valid' naming discrepancies\n",
        "        if not src.exists() and split == \"val\": src = src_root / \"valid\"\n",
        "\n",
        "        dst = target / split\n",
        "        if src.exists():\n",
        "            if dst.exists(): shutil.rmtree(dst)\n",
        "            shutil.copytree(src, dst)\n",
        "            print(f\"‚úÖ Data Organized: {split}\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Warning: Split '{split}' not found in source.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Data Download Failed: {e}\")\n",
        "    print(\"‚ÑπÔ∏è If on HPC without internet, please manually upload dataset to 'data/german'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T76FBBmcqTME",
        "outputId": "2e111ca7-0c16-4b22-e91a-a52fc4aaf293"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è Downloading Dataset via KaggleHub...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/francoismukama/muavic-german-sample?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.99G/8.99G [07:01<00:00, 22.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data Organized: train\n",
            "‚úÖ Data Organized: val\n",
            "‚úÖ Data Organized: test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preprocessing"
      ],
      "metadata": {
        "id": "1Hj7-pU4qiOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Preprocessing ---\n",
        "import os\n",
        "\n",
        "# Ensure PYTHONPATH includes the current directory and Wav2Lip\n",
        "os.environ['PYTHONPATH'] = f\"{os.getcwd()}:{os.getcwd()}/Wav2Lip\"\n",
        "\n",
        "print(\"üöÄ Starting Preprocessing...\")\n",
        "print(\"   (This creates 'audio.wav' and aligned face crops for training)\")\n",
        "\n",
        "!python preprocess_training_data.py \\\n",
        "  --data_root data/german \\\n",
        "  --output_root data/german/preprocessed \\\n",
        "  --filelist_root data/german/filelists \\\n",
        "  --no-zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_vTz-eEqTKL",
        "outputId": "81d609f0-7f79-42c1-e1e0-198812167fb8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Preprocessing...\n",
            "   (This creates 'audio.wav' and aligned face crops for training)\n",
            "üöÄ Preprocessing on cuda\n",
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" to /root/.cache/torch/hub/checkpoints/s3fd-619a316812.pth\n",
            "100% 85.7M/85.7M [00:06<00:00, 13.9MB/s]\n",
            "üé¨ Processing train...\n",
            "  0% 0/9 [00:00<?, ?it/s]^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "9ctuMbikqyE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training ---\n",
        "import os\n",
        "\n",
        "# 1. Set Path for Imports\n",
        "os.environ['PYTHONPATH'] = f\"{os.getcwd()}:{os.getcwd()}/Wav2Lip\"\n",
        "\n",
        "# 2. Check for GPU\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"‚ö†Ô∏è WARNING: No GPU detected. Training will be extremely slow or fail.\")\n",
        "else:\n",
        "    print(f\"‚úÖ GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# 3. Run Training\n",
        "# Note: You can adjust batch_size in 'training/hparams.py' if you hit OOM errors.\n",
        "print(\"üé¨ Starting Wav2Lip Fine-Tuning...\")\n",
        "!python training/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyIpDAWWqTGD",
        "outputId": "dec4491b-9395-4175-956f-af5938c85621"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU Detected: NVIDIA L4\n",
            "üé¨ Starting Wav2Lip Fine-Tuning...\n",
            "‚ùå Critical: Could not import Wav2Lip models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "8a4AsF1_q5Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Full Batch Inference ---\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. Verify FFmpeg (Required for audio processing)\n",
        "if not shutil.which(\"ffmpeg\"):\n",
        "    print(\"‚ùå FFmpeg not found! Please install it (e.g., 'apt-get install ffmpeg' or 'module load ffmpeg').\")\n",
        "else:\n",
        "    print(\"‚úÖ FFmpeg found.\")\n",
        "\n",
        "# 2. Set PYTHONPATH so internal imports work\n",
        "os.environ['PYTHONPATH'] = f\"{os.getcwd()}:{os.getcwd()}/Wav2Lip\"\n",
        "\n",
        "# 3. Define Input/Output\n",
        "# Run on the TEST set to evaluate performance\n",
        "INPUT_DIR = \"data/german/test\"\n",
        "OUTPUT_DIR = \"results/dubbed_test\"\n",
        "\n",
        "# 4. Run the Pipeline\n",
        "print(f\"üöÄ Starting Batch Inference on {INPUT_DIR}...\")\n",
        "!python pipeline/main.py \\\n",
        "    --input_path \"{INPUT_DIR}\" \\\n",
        "    --output_root \"{OUTPUT_DIR}\" \\\n",
        "    --source_lang \"german\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3473GSxQqTED",
        "outputId": "a5c378a5-4adc-4165-a2fc-6d33b083de18"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ FFmpeg found.\n",
            "‚ö†Ô∏è Test video not found at data/german/test/sample.mp4. Please upload a video or check the path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "UQlMQmDOq9au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluation ---\n",
        "import os\n",
        "\n",
        "os.environ['PYTHONPATH'] = f\"{os.getcwd()}:{os.getcwd()}/Wav2Lip\"\n",
        "\n",
        "# Define Paths\n",
        "# GT_PATH = Path to original frames (created during preprocessing)\n",
        "# GEN_PATH = Path to generated video frames (you need to extract them first if evaluating video files)\n",
        "\n",
        "# For demonstration, we assume you want to evaluate the 'test' split processed in Cell 4\n",
        "# Note: To evaluate properly, you need to generate a full validation set using the model.\n",
        "# This cell runs the generic evaluator script on placeholder paths.\n",
        "\n",
        "print(\"üìä Starting Evaluation Script...\")\n",
        "!python evaluate.py \\\n",
        "    --gt_path \"data/german/preprocessed/val\" \\\n",
        "    --gen_path \"dubbing_output/generated_frames_placeholder\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKGp3wjVq63n",
        "outputId": "b28fd277-d920-4bca-8b8a-a42dbd681eb8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Starting Evaluation Script...\n",
            "üöÄ Starting Evaluation on cuda...\n",
            "‚ö†Ô∏è Could not load FaceAlignment: type object 'LandmarksType' has no attribute '_2D'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/lip-sync-dl-f25/evaluate.py\", line 150, in <module>\n",
            "    main()\n",
            "  File \"/content/lip-sync-dl-f25/evaluate.py\", line 94, in main\n",
            "    video_folders = [x for x in gen_root.iterdir() if x.is_dir()]\n",
            "                                ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/pathlib.py\", line 1056, in iterdir\n",
            "    for name in os.listdir(self):\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'dubbing_output/generated_frames_placeholder'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HV5ngULFq--b"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 8879749,
          "sourceId": 13933874,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31193,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "virtual_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}